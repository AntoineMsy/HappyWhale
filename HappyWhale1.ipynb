{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67aae22c-528b-40a2-b710-f66dbb44ac39",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a3a7dd-6b8a-4883-94ff-b1079c2806b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import topk\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581fccb9-0915-4993-a167-d68a14b4b322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaryem_hajji\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install wandb -q\n",
    "import wandb\n",
    "WANDB_NOTEBOOK_NAME=\"first_model_1\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e389f5-234a-4a13-8908-7eb3e5681c40",
   "metadata": {},
   "source": [
    "# Training csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5c64cf-7d2d-45b8-a9ac-a0901b12ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir=\"train_images\"\n",
    "test_images_dir=\"\"\n",
    "train_csv_dir=\"~/train.csv\"\n",
    "test_csv_dir=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e73f7e8-bebe-470e-9fd2-2530beb4e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiv_image_dir(photo_name):\n",
    "    return f'{train_images_dir}/{photo_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c449b9-a47f-470e-abe0-ab497b2d9b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                image             species individual_id\n",
      "0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9\n",
      "1  000562241d384d.jpg      humpback_whale  1a71fbb72250\n",
      "2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b\n",
      "3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063\n",
      "4  00087baf5cef7a.jpg      humpback_whale  8e5253662392\n",
      "0    train_images/00021adfb725ed.jpg\n",
      "1    train_images/000562241d384d.jpg\n",
      "2    train_images/0007c33415ce37.jpg\n",
      "3    train_images/0007d9bca26a99.jpg\n",
      "4    train_images/00087baf5cef7a.jpg\n",
      "Name: image_path, dtype: object\n"
     ]
    }
   ],
   "source": [
    "training_file=pd.read_csv(f\"{train_csv_dir}\")\n",
    "print(training_file.head())\n",
    "\n",
    "training_file[\"image_path\"]= training_file[\"image\"].apply(indiv_image_dir)\n",
    "print(training_file[\"image_path\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1db7c-d85e-440b-ae97-2c781a9e3b6a",
   "metadata": {},
   "source": [
    "# Setting the Encoder: list of labels' numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b016fbb-e5b9-4ac7-bd80-88e25826aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=preprocessing.LabelEncoder()\n",
    "list_of_all_ids=training_file['individual_id']\n",
    "\n",
    "ids_classes=encoder.fit_transform(list_of_all_ids).astype('int32')\n",
    "number_classes=max(ids_classes)+1 #les indices de classes commencent Ã  0\n",
    "training_file[\"ids_classes\"]=ids_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b525243-b241-4393-9169-90a4a387c26a",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdee50a2-7d61-4b58-829b-121f86d44eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhaleDataset(data.Dataset):\n",
    "    def __init__(self, csv):\n",
    "        \n",
    "        self.csv = csv\n",
    "        self.image_list = csv[\"image_path\"]\n",
    "        self.classes_map=csv[\"ids_classes\"]\n",
    "        self.resize = transforms.Compose([\n",
    "                                         transforms.ToPILImage(),\n",
    "                                         transforms.Resize((224,224)),\n",
    "                                         transforms.ToTensor()\n",
    "        ])\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = torchvision.io.read_image(self.image_list.iloc[idx]).float()\n",
    "      \n",
    "        if img.shape[0] == 1:\n",
    "            img = torch.cat((img,img,img))\n",
    "        #img=cv2.imread(img)\n",
    "        img = self.resize(img)\n",
    "        #img=torch.tensor(img)\n",
    "        label = self.classes_map.iloc[idx]\n",
    "        label=torch.tensor(label,dtype=torch.long)\n",
    "        return {\"image\" :img, \"label\": label}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d4b28-54c9-4abc-95ed-f6cf893f7eef",
   "metadata": {},
   "source": [
    "# Training: cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0456ca-db13-4f6b-b25c-65ef3fe72ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_Classifier(nn.Module):\n",
    "    def __init__(self, conv_net, output_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_net = conv_net\n",
    "        self.linear = nn.Linear(output_size, num_classes)\n",
    "    def forward(self, batch_data):\n",
    "        x = self.conv_net(batch_data)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf29105-8f75-45ee-aa6e-3708adf12af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b955dc0-05c4-4c13-9a3a-27f2fc63a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dividing the dataset into 3 folds\n",
    "num_folds=3\n",
    "fold=StratifiedKFold(n_splits=num_folds,shuffle=True,random_state=1)\n",
    "L=enumerate(fold.split(training_file.image,training_file.individual_id))\n",
    "\n",
    "for i, (train_index,validation_index) in L :\n",
    "    training_file.loc[validation_index,\"is_validation\"]=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe0b9a4-9442-4762-8a1c-4554acffc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,dataloader,optimizer,epoch,scheduler,batch_size):\n",
    "    model.train()\n",
    "    print(\"starting training\")\n",
    "    \n",
    "    data_len=0\n",
    "    inter_loss=0.0\n",
    "    \n",
    "    temp=tqdm(enumerate(dataloader))\n",
    "    \n",
    "    for batch, _data in temp:\n",
    "        images=_data['image'].to(device, dtype=torch.float)\n",
    "        labels=_data['label'].to(device, dtype=torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        inter_loss += (loss.item()*batch_size)\n",
    "        data_len += batch_size\n",
    "        \n",
    "        final_loss = inter_loss / data_len\n",
    "        wandb.log({\"train loss\": final_loss})\n",
    "    \n",
    "    \n",
    "    return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64aff90f-6a1c-4fde-b600-4aaf539bf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,dataloader,batch_size,device,epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    data_len=0.0\n",
    "    inter_loss=0.0\n",
    "\n",
    "    temp=tqdm(enumerate(dataloader))\n",
    "    \n",
    "    for batch, _data in temp:\n",
    "        images=_data['image'].to(device, dtype=torch.float)\n",
    "        labels=_data['label'].to(device, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        data_len += batch_size\n",
    "        outputs=model(images)\n",
    "        \n",
    "        loss=loss_function(outputs,labels)\n",
    "        inter_loss += (loss.item()*batch_size)\n",
    "        final_loss = inter_loss / data_len\n",
    "        \n",
    "        wandb.log({\"validation loss\": final_loss})\n",
    "        \n",
    "\n",
    "    return final_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0db113b-7360-43c3-9520-997a7112f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "data_set=WhaleDataset(training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9c84542-c76f-449d-8238-736d83634619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,optimizer,scheduler,device, batch_size=batch_size, epochs=1,data_set=training_file):\n",
    "    wandb.watch(model,log_freq=10)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    for i in range(num_folds):\n",
    "    \n",
    "        kwargs = {'num_workers': 6, 'pin_memory': True} if use_cuda else {}\n",
    "        \n",
    "        train_set=WhaleDataset(data_set[data_set[\"is_validation\"]!=i+1])\n",
    "        validation_set=WhaleDataset(data_set[data_set[\"is_validation\"]==i+1])\n",
    "        \n",
    "        train_loader = data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True,**kwargs)\n",
    "        validation_loader = data.DataLoader(dataset=validation_set,batch_size=batch_size,shuffle=True,**kwargs)\n",
    "\n",
    "        print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1000)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss=train(model,device,train_loader,optimizer,epoch,scheduler,batch_size)\n",
    "            validation_loss=validation(model,validation_loader,batch_size,device,epoch)\n",
    "            \n",
    "            torch.save(model.state_dict(), \"resnet.pt\")\n",
    "\n",
    "        end = time.time()\n",
    "        time_elapsed = end - start\n",
    "        print(time_elapsed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bfbdd5-def2-4b01-9923-c15c270b2086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maryem_hajji/notebooks/wandb/run-20220527_185106-2zlrpyxd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/maryem_hajji/happywhale/runs/2zlrpyxd\" target=\"_blank\">stoic-moon-54</a></strong> to <a href=\"https://wandb.ai/maryem_hajji/happywhale\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track = wandb.init(project='Cross_validation_HappyWhale', \n",
    "                 job_type='Train and Validation',\n",
    "                 tags=['resnet18()'],\n",
    "                 anonymous='must')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2706a90-e79b-4f42-8aab-0f53170796e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = torchvision.models.resnet18(pretrained = True)\n",
    "model = ConvNet_Classifier(conv_model,1000,number_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491f3acf-f2da-43aa-b471-138407d7f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c4fec-3acc-4356-bab2-deb435fb5ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Num Model Parameters 27292099\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [13:40,  5.47s/it, Epoch=1, LR=0.0001, Train_Loss=8.63]\n",
      "75it [07:13,  5.78s/it, Epoch=1, LR=0.0001, validation_Loss=7.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [13:37,  5.45s/it, Epoch=2, LR=0.0001, Train_Loss=6.68]\n",
      "75it [07:04,  5.65s/it, Epoch=2, LR=0.0001, validation_Loss=7.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [13:37,  5.45s/it, Epoch=3, LR=0.0001, Train_Loss=5.16]\n",
      "75it [07:00,  5.61s/it, Epoch=3, LR=0.0001, validation_Loss=7.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 1h 2m 17s\n",
      "Num Model Parameters 27292099\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [13:49,  5.53s/it, Epoch=1, LR=0.0001, Train_Loss=5.94]\n",
      "75it [06:56,  5.56s/it, Epoch=1, LR=0.0001, validation_Loss=4.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [13:25,  5.37s/it, Epoch=2, LR=0.0001, Train_Loss=4.45]\n",
      "47it [04:16,  3.62s/it, Epoch=2, LR=0.0001, validation_Loss=4.99]"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "training(model,optimizer,scheduler,device=device,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb46f9-75ef-4a8b-889c-2de0cf60c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "track.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f569c-73b4-418e-bfed-f1da87015415",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_HappyWhale.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
