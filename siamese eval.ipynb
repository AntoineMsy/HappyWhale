{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c448c28-fb6e-45f8-a262-2c321c2c0a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/inf473v/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ResNet50Classifier.py import Resnet_classifier\n",
    "from SupCon import Embedding_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd97f491-126c-4517-9bec-376a29f5e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4639079-ac27-46c7-9e3e-d0d3efa3be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhaleDataset_eval(data.Dataset):\n",
    "    def __init__(self, csv):\n",
    "        \n",
    "        self.df = pd.read_csv(csv)\n",
    "\n",
    "        self.groups = self.df.groupby('individual_id').groups\n",
    "        self.keys = list(self.groups.keys())\n",
    "        self.label_encoder = {}\n",
    "        for i in range(len(self.keys)):\n",
    "            self.label_encoder[self.keys[i]] = i\n",
    "        \n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):         \n",
    "        img = torchvision.io.read_image(\"train_images_cropped/\" + self.df[\"image\"].iloc[index]).float()\n",
    "\n",
    "        \n",
    "        if img.shape[0] == 1:\n",
    "            img = torch.cat((img,img,img))\n",
    "\n",
    "        label = self.label_encoder[self.df[\"individual_id\"].iloc[index]]\n",
    "    \n",
    "        return {\n",
    "            'image': img,\n",
    "            'id' : label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bd88db-2d94-478e-b653-65c99373adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a simple MLP for predictions\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_size, in_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_size, in_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_size, out_size)\n",
    "        )     \n",
    "    def forward(self,x):\n",
    "        return self.classifier(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cb5e7d-1366-45d5-a1ef-50f015c47f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(model, embedding_model,train_loader, optimizer, criterion,device):\n",
    "      model.train()\n",
    "      for batch_idx, _data in tqdm(enumerate(train_loader)):\n",
    "\n",
    "                image = _data[\"image\"]\n",
    "                \n",
    "                target = _data[\"id\"]\n",
    "\n",
    "                image, target = image.to(device), target.to(device)\n",
    "                with torch.no_grad():\n",
    "                    vect = embedding_model(image)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                pred = model(vect)\n",
    "                loss = criterion(pred,target)\n",
    "                loss.backward()\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db55c7e-7938-4b0f-98f3-884f86af25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, embedding_model, test_loader, criterion,device):\n",
    "    avg_loss = 0\n",
    "    l = len(test_loader)\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, _data in tqdm(enumerate(test_loader)):\n",
    "            image = _data[\"image\"]\n",
    "                \n",
    "            target = _data[\"id\"]\n",
    "            \n",
    "            image, target = image.to(device), target.to(device)\n",
    "            vect = embedding_model(image)\n",
    "            pred = model(vect)\n",
    "                   \n",
    "            loss = criterion(pred,target)\n",
    "            avg_loss += loss/l\n",
    "\n",
    "            #compute accuracy\n",
    "            _, predicted_ids = torch.max(pred,1)\n",
    "            #print((predicted_ids == target).sum().item())\n",
    "            acc += (predicted_ids == target).sum().item()/l/1024\n",
    "    print(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5cd72b-4d28-43ba-96f2-d13cc77766a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, dataset, learning_rate = 5e-3, batch_size = 1024, epochs = 10):\n",
    "    hparams = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    conv_model = torchvision.models.resnet18(pretrained = False)\n",
    "    embedding_model = Embedding_Network(conv_model)\n",
    "    embedding_model.load_state_dict(torch.load(\"res_net_supcon_1.pt\", map_location = torch.device('cuda'))) \n",
    "    embedding_model.to(device)\n",
    "    embedding_model.eval()\n",
    "    \n",
    "    model.to(device)\n",
    "    _, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) -5000,5000])\n",
    "    #test_dataset = WhaleDataset(csv, image_folder, classes_map)\n",
    "    kwargs = {'num_workers': 6, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                \n",
    "                                **kwargs)\n",
    "    test_loader= data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                \n",
    "                                **kwargs)\n",
    "    \"\"\"\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), hparams['learning_rate'])\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    print(\"it # per epoch : \" + str(len(train_loader)))\n",
    "    for i in range(1, epochs+1):\n",
    "        train_mlp(model, embedding_model,train_loader,optimizer,loss,device)\n",
    "        evaluate(model, embedding_model, test_loader,loss,device)\n",
    "    torch.save(model.state_dict(), \"MLP.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b9943-b74d-444d-b93f-d1f323566406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet_Classifier(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.conv_model = torchvision.models.resnet50(pretrained = True)\n",
    "        self.classifier =  nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_size, in_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_size, in_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_size, out_size)\n",
    "        )     \n",
    "        self.linear_classifier = nn.Sequential(nn.Linear(in_size,out_size), nn.Softmax(dim=1))\n",
    "        self.linear = nn.Linear(in_size,out_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, batch_data):\n",
    "        x = self.conv_model(batch_data)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084bae21-4494-4284-90e3-1960e0c2cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15587\n",
      "Num Model Parameters 2043747\n",
      "it # per epoch : 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:43,  1.15it/s]\n",
      "5it [00:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0042968749999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:39,  1.25it/s]\n",
      "5it [00:06,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:40,  1.24it/s]\n",
      "5it [00:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:39,  1.27it/s]\n",
      "5it [00:06,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0041015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:39,  1.25it/s]\n",
      "5it [00:07,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0039062499999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:40,  1.24it/s]\n",
      "5it [00:06,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:40,  1.23it/s]\n",
      "5it [00:07,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005078124999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:40,  1.23it/s]\n",
      "5it [00:06,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0048828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:40,  1.22it/s]\n",
      "5it [00:06,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0062499999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50it [00:39,  1.27it/s]\n",
      "5it [00:06,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0062499999999999995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = WhaleDataset_eval(\"train_corrected.csv\")\n",
    "print(len(dataset.keys))\n",
    "model = MLP(128,len(dataset.keys))\n",
    "#model = Resnet_Classifier(1000,len(dataset.keys))\n",
    "main(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034e4d0-f00d-444b-8eca-ec86ec285dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF473Vchibre",
   "language": "python",
   "name": "inf473v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
